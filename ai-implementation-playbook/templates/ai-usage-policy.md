# AI Tools Acceptable Use Policy

**Template for creating your company's AI usage policy**

---

## Instructions for Use

1. Replace all `[PLACEHOLDER]` text with your company-specific information
2. Review and customize sections based on your industry and risk tolerance
3. Have legal counsel review before implementing
4. Distribute to all employees and contractors
5. Update quarterly as AI landscape evolves

---

# [COMPANY NAME] AI Tools Acceptable Use Policy

**Effective Date**: [DATE]
**Last Updated**: [DATE]
**Policy Owner**: [NAME, TITLE]
**Review Frequency**: Quarterly

---

## 1. Purpose

This policy defines acceptable use of Artificial Intelligence (AI) tools at [COMPANY NAME]. The goal is to enable productivity gains from AI while protecting company data, customer privacy, and compliance obligations.

---

## 2. Scope

This policy applies to:
- All employees (full-time, part-time, contractors)
- All AI tools used for business purposes (approved or unapproved)
- All data processed through AI tools (internal or external)

---

## 3. Approved AI Tools

The following AI tools are approved for business use:

### General-Purpose AI Assistants
- **ChatGPT Plus** ($20/month per user)
  - Use for: Content creation, research, email drafting, analysis
  - Data allowed: Public and Internal (anonymized) data only
  - Contact [IT LEAD] for account setup

- **Claude Pro** ($20/month per user)
  - Use for: Document analysis, long-form writing, code review
  - Data allowed: Public and Internal (anonymized) data only
  - Contact [IT LEAD] for account setup

### Specialized Tools
- **[TOOL NAME]** ($X/month)
  - Use for: [SPECIFIC USE CASE]
  - Data allowed: [DATA TYPES]
  - Contact [OWNER] for access

*[ADD MORE TOOLS AS APPROVED]*

### Enterprise Tools (for Confidential Data)
- **[ENTERPRISE TOOL]** ($X/user/month)
  - Use for: [USE CASES REQUIRING HIGHER SECURITY]
  - Data allowed: Public, Internal, and Confidential data
  - Requires: SSO, manager approval
  - Contact [IT LEAD] for provisioning

---

## 4. Prohibited Tools

**Do NOT use the following without explicit IT approval:**

- Free tier AI tools (ChatGPT Free, Claude Free, Gemini Free)
  - Reason: May use data for training, lack data protections

- Personal AI tool accounts for business work
  - Reason: No company visibility or control, data leakage risk

- Unapproved third-party AI tools
  - Reason: Security review required before use

**To request approval for a new tool**: Submit request to [IT EMAIL] with business justification and tool details.

---

## 5. Data Classification and Allowable Use

### ‚úÖ PUBLIC DATA - Safe for All AI Tools

**Definition**: Information already public or intended for public release

**Examples**:
- Company website content
- Published blog posts, press releases
- Public social media posts
- Product marketing materials
- General industry knowledge

**Approved AI tools**: Any approved tool (including consumer tiers)

---

### ‚ö†Ô∏è INTERNAL DATA - Safe with Consumer Plus Tiers

**Definition**: Internal business information, not public but not highly sensitive

**Examples**:
- Meeting notes (with customer names removed)
- Internal processes and SOPs
- General business strategy discussions
- Marketing plans and campaigns
- Anonymized data and reports
- Generic email templates

**Approved AI tools**: ChatGPT Plus, Claude Pro, [OTHER APPROVED CONSUMER+ TOOLS]

**Requirements**:
- Remove all customer names, emails, phone numbers
- Remove employee names if discussing sensitive topics
- Anonymize company-specific details when possible

---

### üîí CONFIDENTIAL DATA - Enterprise Tools Only

**Definition**: Sensitive business information that would harm company if exposed

**Examples**:
- Customer PII (names, emails, addresses, phone numbers)
- Financial data (revenue, profit margins, bank account info)
- Employee data (salaries, SSNs, performance reviews)
- Contracts with specific terms and pricing
- Pricing strategies and negotiations
- M&A discussions
- Trade secrets, proprietary IP

**Approved AI tools**: [ENTERPRISE TIER TOOLS ONLY - e.g., "ChatGPT Enterprise, Claude Enterprise"]

**Requirements**:
- DPA (Data Processing Agreement) must be in place
- [BAA (Business Associate Agreement) if HIPAA-regulated]
- Manager approval required
- Document what data was processed

**NOT allowed**: Consumer AI tools (even Plus/Pro tiers)

---

### üö´ RESTRICTED DATA - Never in Any AI Tool

**Definition**: Legally protected or extremely sensitive information

**Examples**:
- Credit card numbers, bank account details
- Social Security Numbers, national IDs
- Passwords, API keys, credentials, certificates
- Protected Health Information (PHI) without BAA
- Attorney-client privileged communications
- Government classified information
- Biometric data, genetic information
- Data subject to export controls

**Approved AI tools**: NONE - Process manually or with dedicated compliant tools

**Reason**: Legal/regulatory prohibitions, catastrophic damage if leaked

---

## 6. Anonymization Requirements

Before sharing Internal or Confidential data with AI tools, you must anonymize:

1. **Remove all personal identifiers**:
   - Names ‚Üí "Customer A," "Employee 1," "Client X"
   - Email addresses ‚Üí Remove entirely or "[email]"
   - Phone numbers ‚Üí Remove entirely or "[phone]"
   - Addresses ‚Üí "City, State" only

2. **Remove company identifiers** (when appropriate):
   - Customer company names ‚Üí "Company A," "Partner B"
   - Replace with generic terms when context allows

3. **Generalize specific numbers** (when appropriate):
   - "$2,458,392.17" ‚Üí "approximately $2.5M"
   - Exact dates ‚Üí "Q1 2024" or "early 2024"

4. **Verify anonymization**:
   - Can someone identify the individual/company from this text?
   - If YES ‚Üí anonymize further
   - If NO ‚Üí safe to share

**When in doubt**: Ask [IT LEAD] or [LEGAL CONTACT] before sharing.

---

## 7. Acceptable Use Guidelines

### ‚úÖ DO:

1. **Use AI to increase productivity**
   - Draft emails, documents, reports
   - Analyze data, generate insights
   - Research topics, summarize information
   - Create content (blogs, social posts, marketing copy)

2. **Review and edit all AI outputs**
   - AI is a draft assistant, not a final product generator
   - Verify factual accuracy
   - Add your expertise and judgment
   - Ensure brand voice and quality standards

3. **Anonymize sensitive data**
   - Remove customer and employee names
   - Follow data classification guidelines above
   - When unsure, over-anonymize

4. **Use approved tools only**
   - Tools listed in Section 3
   - Request approval for new tools via [IT EMAIL]

5. **Report concerns**
   - If you accidentally shared sensitive data with AI, report to [IT LEAD] immediately
   - If you see someone violating policy, report to [MANAGER/HR]

### ‚ùå DON'T:

1. **Don't share Restricted or Confidential data with consumer AI tools**
   - No customer PII, financial data, trade secrets
   - Use enterprise tools with proper protections

2. **Don't auto-send AI outputs without review**
   - Always verify accuracy
   - Add personal touches
   - Check for brand voice and tone

3. **Don't use unapproved tools**
   - Free tiers of AI tools
   - Personal accounts for business work
   - New tools without IT security review

4. **Don't rely solely on AI for critical decisions**
   - Legal advice, financial decisions, hiring choices
   - AI informs decisions, humans make them
   - Consult relevant experts

5. **Don't plagiarize**
   - AI outputs may be similar to copyrighted sources
   - Always verify originality
   - Run content through plagiarism checker if publishing

---

## 8. Industry-Specific Restrictions

*[CUSTOMIZE BASED ON YOUR INDUSTRY]*

### For Healthcare (HIPAA-Regulated)

**Additional restrictions**:
- ‚ùå NO Protected Health Information (PHI) in any AI tool without BAA
- ‚ùå NO patient names, MRNs, diagnoses, treatment plans
- ‚úÖ ONLY use AI tools with signed Business Associate Agreement
- ‚úÖ Approved tools for PHI: [LIST TOOLS WITH BAA]

**Allowed use cases** (with BAA):
- Medical literature research (no PHI)
- Clinical note templates (generic, no patient data)
- Anonymized case discussions

---

### For Financial Services (SOX, PCI-DSS)

**Additional restrictions**:
- ‚ùå NO credit card numbers (PCI-DSS scope)
- ‚ùå NO non-public financial data or trading strategies
- ‚ùå NO customer financial information
- ‚úÖ ONLY use SOC 2 Type II compliant tools for financial analysis

**Allowed use cases**:
- Market research (public data)
- Email drafting (no customer financial data)
- Financial modeling templates (no real customer data)

---

### For Legal Services

**Additional restrictions**:
- ‚ùå NO attorney-client privileged communications
- ‚ùå NO client case details (unless fully anonymized)
- ‚ùå NO confidential agreements or litigation strategy
- ‚úÖ Prioritize tools with strong privacy commitments

**Allowed use cases**:
- Legal research (public case law)
- Contract template drafting (generic)
- Document review (fully anonymized)

---

*[REMOVE SECTIONS ABOVE THAT DON'T APPLY TO YOUR INDUSTRY]*

---

## 9. Training Requirements

All employees must:

1. **Complete AI policy training** within 30 days of hire or policy publication
   - Duration: 30-minute session
   - Content: Data classification, approved tools, do's and don'ts
   - Quiz: Must score 80% to pass
   - Contact [TRAINING LEAD] to schedule

2. **Acknowledge policy** in writing
   - Sign acknowledgment form
   - Submit to [HR/IT]
   - Stored in personnel file

3. **Annual refresher training**
   - Updates on new tools, policy changes
   - Review of data classification
   - Scheduled by [TRAINING LEAD]

---

## 10. Security and Privacy

### Data Handling

1. **Minimize data shared with AI**
   - Share only what's needed for the task
   - Avoid copy-pasting entire databases or customer lists

2. **Delete conversations when done** (if tool allows)
   - ChatGPT: Can delete chat history
   - Claude: Can delete conversations
   - Check tool settings for data retention options

3. **Use enterprise tools for confidential data**
   - Enterprise tiers have contractual data protections
   - Consumer tools lack legal guarantees

### Access Controls

1. **Company-provided accounts only**
   - All AI tool accounts provisioned by IT
   - No personal accounts for business use
   - SSO (Single Sign-On) required for enterprise tools

2. **Principle of least privilege**
   - Request only tools needed for your role
   - Manager approval for enterprise tool access

3. **Offboarding**
   - AI tool access revoked upon employee departure
   - Conversations exported if needed for business continuity

---

## 11. Monitoring and Auditing

[COMPANY NAME] reserves the right to:

1. **Monitor AI tool usage**
   - Track which tools are being used
   - Review prompts and outputs (enterprise tools with admin features)
   - Audit for policy compliance

2. **Conduct quarterly audits**
   - Random sample of AI tool usage
   - Verify data classification compliance
   - Interview employees about AI practices

3. **Investigate incidents**
   - If sensitive data exposure suspected
   - If policy violations reported
   - Work with employee to resolve and prevent recurrence

**Note**: Monitoring is for security and compliance, not micromanagement. We encourage AI use within policy guidelines.

---

## 12. Incident Response

### If You Accidentally Share Sensitive Data with AI:

1. **Immediately**:
   - Stop using the tool
   - Delete the conversation (if possible)
   - Screenshot what was shared (for investigation)

2. **Within 1 hour**:
   - Report to [IT LEAD]: [EMAIL/PHONE]
   - Provide details: What tool, what data, when
   - Don't hide it - early reporting prevents bigger issues

3. **IT will**:
   - Assess severity (low/medium/high risk)
   - Request data deletion from vendor (if possible)
   - Determine if customer notification required (GDPR, CCPA)
   - Document incident for compliance records

4. **Follow-up**:
   - Retrain on data classification
   - Update processes to prevent recurrence
   - No disciplinary action for honest mistakes reported promptly

**Severity levels**:
- **Low risk**: Internal data shared with Plus/Pro tier
- **Medium risk**: Customer PII shared with consumer tool
- **High risk**: Financial data, credentials, PHI, or Restricted data shared

---

## 13. Consequences for Policy Violations

[COMPANY NAME] takes data protection seriously. Policy violations will result in:

### First Violation (unintentional):
- Warning and retraining
- Documented in personnel file
- Additional monitoring of AI tool usage

### Second Violation:
- Written warning
- Suspension of AI tool access (30-90 days)
- Manager discussion and performance improvement plan

### Serious Violations (intentional or egregious):
- Immediate suspension of AI tool access
- Disciplinary action up to termination
- Potential legal action if data breach occurred

**Examples of serious violations**:
- Intentionally sharing customer PII with unapproved tools
- Using AI to circumvent security controls
- Sharing company trade secrets with AI for personal projects
- Repeatedly violating policy after retraining

**Note**: We distinguish between honest mistakes (reported quickly) and negligent or intentional violations.

---

## 14. Policy Updates and Communication

This policy will be:

1. **Reviewed quarterly** by [POLICY OWNER]
   - Updated for new tools, regulations, incidents
   - Input from IT, Legal, Compliance, business leaders

2. **Communicated via**:
   - All-hands announcements for major changes
   - Email updates for minor clarifications
   - Slack [CHANNEL NAME] for Q&A and tips
   - Updated on company intranet at [LINK]

3. **Version controlled**:
   - Previous versions archived at [LOCATION]
   - Change log maintained in Section 16

---

## 15. Questions and Support

### General Questions
- Email: [AI-QUESTIONS@COMPANY.COM]
- Slack: [#ai-tools]
- Office Hours: [SCHEDULE]

### Tool Access Requests
- Contact: [IT LEAD]
- Email: [IT-EMAIL]
- Expected turnaround: 2-3 business days

### Data Classification Questions
- Contact: [DATA CLASSIFICATION OWNER]
- Email: [EMAIL]
- When unsure: Treat as Confidential and ask before sharing

### Policy Violations or Concerns
- Contact: [COMPLIANCE/HR]
- Email: [EMAIL]
- Anonymous hotline: [PHONE/LINK if applicable]

---

## 16. Acknowledgment

I, [EMPLOYEE NAME], acknowledge that I have read, understood, and agree to comply with [COMPANY NAME]'s AI Tools Acceptable Use Policy.

I understand that:
- Violations may result in disciplinary action up to termination
- I must follow data classification guidelines when using AI tools
- I will report any policy violations or data exposure incidents immediately
- This policy may be updated, and I will be notified of changes

**Signature**: ___________________________
**Date**: ___________________________
**Employee ID**: ___________________________

**[Company Rep] Signature**: ___________________________
**Date**: ___________________________

---

## 17. Version History

| Version | Date | Changes | Author |
|---------|------|---------|--------|
| 1.0 | [DATE] | Initial policy release | [NAME] |
| | | | |
| | | | |

---

## 18. Appendix: Quick Reference Card

**Print this page and keep at your desk**

### ‚úÖ Safe to Share with AI

**Public Data**:
- Website content
- Press releases
- Marketing materials

**Internal Data** (with anonymization):
- Meeting notes (remove names)
- SOPs and processes
- Strategy docs (remove specifics)

### ‚ùå Never Share with AI

- Customer names, emails, phones
- Employee SSNs, salaries
- Credit cards, bank accounts
- Passwords, API keys
- Trade secrets

### When in Doubt

**Ask yourself**: "Would I be comfortable if this appeared in a data breach?"
- If NO ‚Üí Don't share with AI
- If MAYBE ‚Üí Anonymize first or ask [IT LEAD]
- If YES ‚Üí Safe to share

**Quick anonymization**:
1. Replace names: "Customer A," "Employee 1"
2. Remove emails and phones
3. Generalize numbers: "$2.5M" instead of "$2,458,392"

**Report incidents**: [IT EMAIL] or [PHONE]

---

**END OF POLICY**
